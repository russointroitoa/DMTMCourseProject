{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section we show the models that we have implemented in our solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_model import run_model\n",
    "from algorithms.XGBoost import run_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useTest = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Standard\n",
    "LightGBM_std takes into account all the different products in the dataset. We chose it for its flexibility, efficiency, speed and ability to deal with categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_std'\n",
    "run_model(name, useTest=useTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Cluster\n",
    "Unlike the previous model, in LightGBM_cls the dataset is restricted to clusters and we train and predict on the SKUs of the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_cls'\n",
    "run_model(name, useTest=useTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "CatBoost exploits all the dataset as LightGBM_std and we chose it because it is specifically designed to handle categorical data and doesn't need hard parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'catboost'\n",
    "run_model(name, useTest=useTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Incremental\n",
    "We chose XGBoost with an incremetal approach because it allows an incremental training, in which the model generated is unique and at each step its trees are updated, without generating new ones. This increases a lot the speed of the model at the cost of slightly worse performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_xgboost(useTest=False, useScope=False, completeCV = True, dataAugm=True, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Final Model - Stacking**\n",
    "Our final model is based on a Stacking approach, using Linear Regression as meta-learner. <br> The predictions inside the stacking have been taken from the models above.\n",
    "To run the stacking, follow the guidelines on _notebooks/00_Summary_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Other Models\n",
    "We have tried also other model like ARIMA, Linear Regression and Random Forest but we have decided to not show them because of their poor performances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
